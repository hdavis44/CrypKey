{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3bfa196",
   "metadata": {},
   "source": [
    "# Data import & exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fadbd3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade448b6",
   "metadata": {},
   "source": [
    "## Path of data\n",
    "downloaded from: https://www.kaggle.com/c/fake-news/data?select=test.csv\n",
    "```sh\n",
    "├── raw_data\n",
    "│   └── fake-news\n",
    "│       ├── submit.csv\n",
    "│       ├── test.csv\n",
    "│       └── train.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0001f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: ../raw_data/fake-news/: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../raw_data/fake-news/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab553457",
   "metadata": {},
   "source": [
    "## load data & basic exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6710306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc82a4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "772f9501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26468c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10413\n",
       "0    10387\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6096f8",
   "metadata": {},
   "source": [
    ">**The data is balanced, between fake and real** 👍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2cfe4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "title     object\n",
       "author    object\n",
       "text      object\n",
       "label      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0de55546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f259da",
   "metadata": {},
   "source": [
    ">**data contains `NaN` - will remove** and at the same time drop `title` and `author`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dec7f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1\n",
       "1  Ever get the feeling your life circles the rou...      0\n",
       "2  Why the Truth Might Get You Fired October 29, ...      1\n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1\n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['text', 'label']].dropna(axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bcd953",
   "metadata": {},
   "source": [
    "**Let's look at a full text...** (below)\n",
    "\n",
    "Things to fix,a apart from the usual = remove new-line `\\n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dde4ec1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'House Dem Aide: We Didn’t Even See Comey’s Letter Until Jason Chaffetz Tweeted It By Darrell Lucus on October 30, 2016 Subscribe Jason Chaffetz on the stump in American Fork, Utah ( image courtesy Michael Jolley, available under a Creative Commons-BY license) \\nWith apologies to Keith Olbermann, there is no doubt who the Worst Person in The World is this week–FBI Director James Comey. But according to a House Democratic aide, it looks like we also know who the second-worst person is as well. It turns out that when Comey sent his now-infamous letter announcing that the FBI was looking into emails that may be related to Hillary Clinton’s email server, the ranking Democrats on the relevant committees didn’t hear about it from Comey. They found out via a tweet from one of the Republican committee chairmen. \\nAs we now know, Comey notified the Republican chairmen and Democratic ranking members of the House Intelligence, Judiciary, and Oversight committees that his agency was reviewing emails it had recently discovered in order to see if they contained classified information. Not long after this letter went out, Oversight Committee Chairman Jason Chaffetz set the political world ablaze with this tweet. FBI Dir just informed me, \"The FBI has learned of the existence of emails that appear to be pertinent to the investigation.\" Case reopened \\n— Jason Chaffetz (@jasoninthehouse) October 28, 2016 \\nOf course, we now know that this was not the case . Comey was actually saying that it was reviewing the emails in light of “an unrelated case”–which we now know to be Anthony Weiner’s sexting with a teenager. But apparently such little things as facts didn’t matter to Chaffetz. The Utah Republican had already vowed to initiate a raft of investigations if Hillary wins–at least two years’ worth, and possibly an entire term’s worth of them. Apparently Chaffetz thought the FBI was already doing his work for him–resulting in a tweet that briefly roiled the nation before cooler heads realized it was a dud. \\nBut according to a senior House Democratic aide, misreading that letter may have been the least of Chaffetz’ sins. That aide told Shareblue that his boss and other Democrats didn’t even know about Comey’s letter at the time–and only found out when they checked Twitter. “Democratic Ranking Members on the relevant committees didn’t receive Comey’s letter until after the Republican Chairmen. In fact, the Democratic Ranking Members didn’ receive it until after the Chairman of the Oversight and Government Reform Committee, Jason Chaffetz, tweeted it out and made it public.” \\nSo let’s see if we’ve got this right. The FBI director tells Chaffetz and other GOP committee chairmen about a major development in a potentially politically explosive investigation, and neither Chaffetz nor his other colleagues had the courtesy to let their Democratic counterparts know about it. Instead, according to this aide, he made them find out about it on Twitter. \\nThere has already been talk on Daily Kos that Comey himself provided advance notice of this letter to Chaffetz and other Republicans, giving them time to turn on the spin machine. That may make for good theater, but there is nothing so far that even suggests this is the case. After all, there is nothing so far that suggests that Comey was anything other than grossly incompetent and tone-deaf. \\nWhat it does suggest, however, is that Chaffetz is acting in a way that makes Dan Burton and Darrell Issa look like models of responsibility and bipartisanship. He didn’t even have the decency to notify ranking member Elijah Cummings about something this explosive. If that doesn’t trample on basic standards of fairness, I don’t know what does. \\nGranted, it’s not likely that Chaffetz will have to answer for this. He sits in a ridiculously Republican district anchored in Provo and Orem; it has a Cook Partisan Voting Index of R+25, and gave Mitt Romney a punishing 78 percent of the vote in 2012. Moreover, the Republican House leadership has given its full support to Chaffetz’ planned fishing expedition. But that doesn’t mean we can’t turn the hot lights on him. After all, he is a textbook example of what the House has become under Republican control. And he is also the Second Worst Person in the World. About Darrell Lucus \\nDarrell is a 30-something graduate of the University of North Carolina who considers himself a journalist of the old school. An attempt to turn him into a member of the religious right in college only succeeded in turning him into the religious right\\'s worst nightmare--a charismatic Christian who is an unapologetic liberal. His desire to stand up for those who have been scared into silence only increased when he survived an abusive three-year marriage. You may know him on Daily Kos as Christian Dem in NC . Follow him on Twitter @DarrellLucus or connect with him on Facebook . Click here to buy Darrell a Mello Yello. Connect'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2c4d91",
   "metadata": {},
   "source": [
    "# Text Preprocessing (as a function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d463cdf6",
   "metadata": {},
   "source": [
    "## Data load function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94f2061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    df = pd.read_csv('../raw_data/train.csv')\n",
    "    df = df[['text', 'label']].dropna(axis=0)\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac6dfc9",
   "metadata": {},
   "source": [
    "## Clean Text Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe3b5b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "import unidecode\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # remove new-line: /n\n",
    "    text = text.replace('\\n', ' ')\n",
    "    \n",
    "    # Remove Punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ')\n",
    "    \n",
    "    # Lower Case\n",
    "    text = text.lower() \n",
    "    \n",
    "    # Remove Accents\n",
    "    text = unidecode.unidecode(text) \n",
    "    \n",
    "    # Tokenize --> (make word list) -> useful for following operation\n",
    "    token_text = word_tokenize(text) \n",
    "    \n",
    "    # Remove numbers\n",
    "    token_text = [word for word in token_text if word.isalpha()] \n",
    "    \n",
    "    # Stemming 👉 cut to the common root (sometimes no at real word)\n",
    "    #stemmer = PorterStemmer()\n",
    "    #token_text = [stemmer.stem(word) for word in token_text]\n",
    "    \n",
    "    # Lemming 👉 base word by meaning (laanguage correct)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    token_text = [lemmatizer.lemmatize(word) for word in token_text]\n",
    "    \n",
    "    # Remove Stop Words\n",
    "    # 👍 useful for topic modelling, sentiment analysis\n",
    "    # 👎 Useless for authorship attribution 🍎\n",
    "    stop_words = set(stopwords.words('english'))     \n",
    "    token_text = [word for word in token_text if not word in stop_words] \n",
    "    \n",
    "    return \" \".join(token_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f55ee",
   "metadata": {},
   "source": [
    "# Load & Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b55b95fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88bcba92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20761, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf8283",
   "metadata": {},
   "source": [
    "**Split data into Train & Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20255de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['text']], df['label'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e8fa7a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14532, 1), (6229, 1), (14532,), (6229,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f40143b",
   "metadata": {},
   "source": [
    "**Run clening function on `X_train` and `X_test`**\n",
    "\n",
    "🚨 this will take som time... ⏱ 2.5 min on my machine, which is fairly fast (I hope..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "206facca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 7s, sys: 583 ms, total: 2min 8s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_clean = X_train['text'].apply(clean_text)\n",
    "X_test_clean = X_test['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd146f0c",
   "metadata": {},
   "source": [
    "# Vectorizing X - with `TfidfVectorizer()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e5b95c",
   "metadata": {},
   "source": [
    "**Running with default**, but following params could be tweeked:\n",
    "* ngram_range=(1, 1),\n",
    "* max_df=1.0,\n",
    "* min_df=1,\n",
    "* max_features=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcd642a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2, 2))\n",
    "\n",
    "X_train_vector = vectorizer.fit_transform(X_train_clean)\n",
    "X_test_vector = vectorizer.transform(X_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46b5dbf",
   "metadata": {},
   "source": [
    "**result shapes** 🥺"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "000b6398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14532, 3121799), (6229, 3121799))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vector.shape, X_test_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fe9d6e",
   "metadata": {},
   "source": [
    "# Naive Bayes Algorithm - `MultinomialNB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e655c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfa337f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 143 ms, sys: 23.7 ms, total: 167 ms\n",
      "Wall time: 169 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=2, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Modle\n",
    "nb_model = MultinomialNB(alpha=2)\n",
    "\n",
    "# Model fit\n",
    "nb_model.fit(X_train_vector, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e9fe167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945637214423342"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model score on TRAIN-data\n",
    "nb_model.score(X_train_vector, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2173b7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9017498795954407"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model score on TEST-data\n",
    "nb_model.score(X_test_vector, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70955c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c85a877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be34f38a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b87c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad533f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39acf26a",
   "metadata": {},
   "source": [
    "# ⚠️ Below code is for reading - is not functional ⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf44e7",
   "metadata": {},
   "source": [
    "## Encoder function for `Pipelines` - 🧰 work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bea0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class TimeFeaturesEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        kjsnbjkfbeafv\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, time_column, time_zone_name='America/New_York'):\n",
    "        self.time_column = time_column\n",
    "        self.time_zone_name = time_zone_name\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        X_ = X.copy()\n",
    "        \n",
    "        # X_ = X.apply(clean_text)\n",
    "        \n",
    "        X_.index = pd.to_datetime(X[self.time_column])\n",
    "        X_.index = X_.index.tz_convert(self.time_zone_name)\n",
    "        X_[\"dow\"] = X_.index.weekday\n",
    "        X_[\"hour\"] = X_.index.hour\n",
    "        X_[\"month\"] = X_.index.month\n",
    "        X_[\"year\"] = X_.index.year\n",
    "        return X_[['dow', 'hour', 'month', 'year']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f79bdb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b3f3828",
   "metadata": {},
   "source": [
    "## Example of - Feature engineering\n",
    "Sometimes, you may want to extract your own features from the texts. Some common features are:\n",
    "\n",
    "* Vocabulary Richness\n",
    "* Average word per line\n",
    "* Digit/Character ratio\n",
    "* Anything you can think of that relates to the task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1b32af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i do not love football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love football not basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>football football football</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text\n",
       "0          i do not love football\n",
       "1  i love football not basketball\n",
       "2      football football football"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame([\n",
    "    'i do not love football', \n",
    "    'i love football not basketball',\n",
    "    'football football football'\n",
    "], columns=['text'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "244fc572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>vocab richness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i do not love football</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love football not basketball</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>football football football</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text  vocab richness\n",
       "0          i do not love football        1.000000\n",
       "1  i love football not basketball        1.000000\n",
       "2      football football football        0.333333"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def vocab_richness(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    total_length = len(tokens)\n",
    "    unique_words = set(tokens)\n",
    "    unique_word_length = len(unique_words)\n",
    "    return unique_word_length/total_length\n",
    "\n",
    "data['vocab richness'] = data.text.apply(vocab_richness)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcf9f4e",
   "metadata": {},
   "source": [
    "## Tuning vectorizer and model simultanously\n",
    "Different vectorizing hyperparameters will affect model performance. As such, it is important to tune the hyperparameters of both the vectorizer and the model simultaneously. This can be done by using a Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a742e57",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5d/77ljc9f558lc946_x757yb340000gn/T/ipykernel_16091/3126589884.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                            refit=True, cv=5)\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Set parameters to search\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1,1), (2,2)),\n",
    "    'nb__alpha': (0.1,1)}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, \n",
    "                           verbose=1, scoring = \"accuracy\", \n",
    "                           refit=True, cv=5)\n",
    "\n",
    "test = grid_search.fit(data.text,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb6a7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f698fd54",
   "metadata": {},
   "source": [
    "## Combining vectorizer output and engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b46e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def vocab_richness(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    total_length = len(tokens)\n",
    "    unique_words = set(tokens)\n",
    "    unique_word_length = len(unique_words)\n",
    "    return unique_word_length/total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vocab_richness'] = data.text.apply(vocab_richness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcedf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d24cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "# Data\n",
    "X = data[['text', 'vocab_richness']]\n",
    "y = data.label\n",
    "\n",
    "# selective column transformer for the pipeline\n",
    "column_trans = ColumnTransformer([('vec', CountVectorizer(), 'text')]\n",
    "                                 , remainder='passthrough')\n",
    "\n",
    "# Assemble Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', column_trans),\n",
    "    ('nb', MultinomialNB()),])\n",
    "\n",
    "# 5-Fold Cross validate model\n",
    "cv_results = cross_validate(pipeline, X, y, \n",
    "                            cv=5, \n",
    "                            scoring=['accuracy',\n",
    "                                     'precision',\n",
    "                                     'recall'],\n",
    "                            n_jobs=-1\n",
    "                           )\n",
    "pd.DataFrame(cv_results) # Cross validation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85da04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results['test_accuracy'].mean(), cv_results['test_precision'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e74b7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

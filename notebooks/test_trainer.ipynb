{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ceca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71cbfffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b1a10fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import pipe\n",
    "from detecting_fake_news.data import get_local_data, get_cloud_data\n",
    "from detecting_fake_news.preprocessing import TextPreprocessor\n",
    "from detecting_fake_news.params import BUCKET_NAME, BUCKET_TRAIN_DATA_PATH, LOCAL_TRAIN_DATA_PATH\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from termcolor import colored\n",
    "from detecting_fake_news.gcp import storage_upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211960ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO:\n",
    "\n",
    "# add MLFlow functionality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cca42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    '''\n",
    "    The Trainer class fits trains, evaluates, and saves an NLP model.\n",
    "    The main method is Trainer.run, which takes a dataframe as an argument.\n",
    "    When instantiating an instance of the Trainer class, you provide two\n",
    "    arguments, X_col and y_col, which correspond to the column names of your\n",
    "    feature and label respectively.\n",
    "    '''\n",
    "    def __init__(self, X_col, y_col):\n",
    "        self.X_col = X_col\n",
    "        self.y_col = y_col\n",
    "        self.pipe = None\n",
    "        self.model = None\n",
    "\n",
    "    def set_pipeline(self):\n",
    "        '''resets self.pipe and self.model to None then sets self.pipe'''\n",
    "        self.pipe = None\n",
    "        self.model = None\n",
    "        pipe = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(ngram_range=(2, 2))),\n",
    "            ('nbmodel', MultinomialNB())])\n",
    "        self.pipe = pipe\n",
    "\n",
    "    def run(self, df):\n",
    "        '''accepts a dataframe; preprocesses and splits data into train/test;\n",
    "           fits a pipeline to X_train, y_train; evaluates on X_test, y_test;\n",
    "           prints an accuracy score'''\n",
    "        print(\"dropping rows of empty text\")\n",
    "        df = df.dropna(subset=[self.X_col])\n",
    "        X = df[[self.X_col]]\n",
    "        y = df[self.y_col]\n",
    "        print(\"preprocessing data with following parameters:\")\n",
    "        preproc = TextPreprocessor()\n",
    "        for k,v in vars(preproc).items():\n",
    "            if v == True:\n",
    "                print(f\"{k}, \",end='')\n",
    "        print('')\n",
    "        X_clean = preproc.transform(X)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_clean, y, test_size=0.25)\n",
    "        print(\"setting pipeline\")\n",
    "        self.set_pipeline()\n",
    "        print(\"vectorizing data and fitting model\")\n",
    "        self.model = self.pipe.fit(X_train, y_train)\n",
    "        print(\"evaluating on test data\")\n",
    "        self.evaluate(X_test, y_test)\n",
    "\n",
    "    def save_model_locally(self, model):\n",
    "        '''save the model into a .joblib format'''\n",
    "        joblib.dump(model, 'model.joblib')\n",
    "        print(colored(\"model.joblib saved locally\", \"green\"))\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        '''predicts y_pred based on X_test and scores accuracy on y_test'''\n",
    "        if self.model:\n",
    "            y_pred = self.model.predict(X_test)\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "            print(colored(f\"model accuracy: {score}\", \"green\"))\n",
    "        else:\n",
    "            print(\"please train a model first using Trainer.run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2cd3cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting 3000 rows of cloud data\n",
      "dropping rows of empty text\n",
      "preprocessing data with following parameters:\n",
      "new_line, punct, lower, accent, numbers, lemm, stop_words, \n",
      "setting pipeline\n",
      "vectorizing data and fitting model\n",
      "evaluating on test data\n",
      "\u001b[32mmodel accuracy: 0.8664886515353805\u001b[0m\n",
      "\u001b[32mmodel.joblib saved locally\u001b[0m\n",
      "\u001b[32m=> model.joblib uploaded to bucket wagon-data-745-fake-news-data inside models/MultinomialNB/model.joblib\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df = get_cloud_data(nrows=3000)\n",
    "trainer = Trainer('text', 'label')\n",
    "trainer.run(df)\n",
    "trainer.save_model_locally(trainer.model)\n",
    "storage_upload('models/MultinomialNB/model.joblib', 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d18e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "testpre = TextPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a43974f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_line, punct, lower, accent, numbers, lemm, stop_words, "
     ]
    }
   ],
   "source": [
    "for k,v in vars(testpre).items():\n",
    "    if v == True:\n",
    "        print(f\"{k}, \", end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10cce9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'new_line': True, 'punct': True, 'lower': True, 'accent': True, 'numbers': True, 'stemm': False, 'lemm': True, 'stop_words': True}\n"
     ]
    }
   ],
   "source": [
    "print(vars(testpre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655aa355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
